{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group No. : 20\n",
    "\n",
    "### 20CS60R61 : Murtaza Saifee\n",
    "### 20CS60R62 : Nikhil Kumar\n",
    "### 20CS60R65 : Saurav Koranga\n",
    "\n",
    "### Mini Project 1\n",
    "\n",
    "### Title : NSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"nursery.csv\", encoding = \"ISO-8859-1\")\n",
    "test = pd.read_csv(\"nursery_test.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(decisionTree, testData):\n",
    "    feature = list(decisionTree.keys())[0]\n",
    "    try:\n",
    "        branch = decisionTree[feature][testData[feature]]\n",
    "    except:\n",
    "        branch = decisionTree[feature][list(decisionTree[feature].keys())[0]]\n",
    "    if isinstance(branch, dict):\n",
    "        return classification(branch, testData)\n",
    "    else:\n",
    "        return branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_and_error(decisionTree, test, flag):\n",
    "    matches = []\n",
    "    tree_true = []\n",
    "    tree_pred = []\n",
    "    for i in range(len(test)):\n",
    "        result = classification(decisionTree, test.iloc[i])\n",
    "        matches.append((result, test.iloc[i][-1]))\n",
    "        tree_true.append(test.iloc[i][-1])\n",
    "        tree_pred.append(result)\n",
    "\n",
    "    if flag == 2:\n",
    "        count_correct = 0\n",
    "        count_error = 0\n",
    "        for tup in matches:\n",
    "            if tup[0] == tup[1]:\n",
    "                count_correct += 1\n",
    "            else:\n",
    "                count_error += 1\n",
    "        #print(count_correct, \" \", count_error)\n",
    "        return count_correct, count_error\n",
    "        \n",
    " \n",
    "    if flag == 1:\n",
    "        report = classification_report(tree_true, tree_pred, zero_division = 0)\n",
    "    else:\n",
    "        report = []\n",
    "    accuracy = accuracy_score(tree_true, tree_pred)\n",
    "            \n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1A. Entropy Based Desicion Tree Medelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(inptArr):\n",
    "    uniqueClass, countClass = np.unique(inptArr[:, -1], return_counts = True)\n",
    "    entropy = 0\n",
    "    i = 0\n",
    "    while i < len(uniqueClass):\n",
    "        entropy += -(countClass[i]/len(inptArr))*log((countClass[i]/len(inptArr)), 2)\n",
    "        i += 1\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_infoGain(inptdf, inptArr, attribute):\n",
    "    entropyS = calc_entropy(inptArr)\n",
    "    attrIndex = np.where(np.array(inptdf.columns) == attribute)[0][0]\n",
    "    attrVal, valCount = np.unique(inptArr[:, attrIndex], return_counts = True)\n",
    "    infoGain = 0\n",
    "    entSum = 0\n",
    "    i = 0\n",
    "    for i in range(0, len(attrVal)):\n",
    "        value_frac = valCount[i]/len(inptArr)\n",
    "        curr = inptArr[inptArr[:, attrIndex] == attrVal[i]]\n",
    "        entSum += value_frac * calc_entropy(curr)\n",
    "    infoGain = entropyS - entSum\n",
    "    return infoGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_attribute(inptdf, inptArr):\n",
    "    attrSet = np.array(inptdf.columns)\n",
    "    maxInfoGain = -1\n",
    "    bestAttr = 'NULL'\n",
    "    for i in range(0, (len(attrSet) - 1)):\n",
    "        infoGain = calc_infoGain(inptdf, inptArr, attrSet[i])\n",
    "        if infoGain > maxInfoGain:\n",
    "            maxInfoGain = infoGain\n",
    "            bestAttr = attrSet[i]\n",
    "    return bestAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_dataframe(inptdf, attr,value):\n",
    "    subT = inptdf[inptdf[attr] == value]\n",
    "    pd.RangeIndex(len(subT.index))\n",
    "    return subT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(inptdf, decisionTree = None):\n",
    "    inptArr = inptdf.values\n",
    "    attr = best_attribute(inptdf, inptArr)\n",
    "    attrIndex = np.where(np.array(inptdf.columns) == attr)[0][0]\n",
    "    attrVal = np.unique(inptArr[:, attrIndex])\n",
    "    if decisionTree is None:\n",
    "        decisionTree = {}\n",
    "        decisionTree[attr] = {}\n",
    "    i = 0\n",
    "    while i < len(attrVal):\n",
    "        subT = val_dataframe(inptdf, attr, attrVal[i])\n",
    "        classVal = np.unique(subT[subT.columns[-1]])\n",
    "        if len(classVal) != 1:\n",
    "            decisionTree[attr][attrVal[i]] = decision_tree(subT)\n",
    "        else:\n",
    "            decisionTree[attr][attrVal[i]] = classVal[0]\n",
    "        i += 1\n",
    "    return decisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_DT = decision_tree(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1B. sklearn Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:,-1:]\n",
    "x_test = test.iloc[:,:-1]\n",
    "y_test = test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "train_encode = ohe.fit_transform(x_train)\n",
    "test_encode = ohe.fit_transform(x_test)\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(train_encode,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_encode)\n",
    "acc_dt_sklearn = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of Decision Tree(Entropy) using Sklearn: \"+ str(acc_dt_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2A. Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {}\n",
    "import copy\n",
    "\n",
    "tree = copy.deepcopy(entropy_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = np.array(train.columns)\n",
    "label = attributes[len(attributes)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, key, value):\n",
    "    attr_list = df[df[key] == value]\n",
    "    return attr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_result(tree, train, test):\n",
    "    \n",
    "    leaf = train[label].value_counts().index[0]\n",
    "    errors_leaf = sum(test[label] != leaf)\n",
    "    x, errors_decision_node = correct_and_error(tree, test, 2)\n",
    "\n",
    "    if errors_leaf <= errors_decision_node:\n",
    "        #print('return leaf--'+str(leaf))\n",
    "        return leaf\n",
    "    else:\n",
    "        #print('return tree')\n",
    "        return tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_pruning(tree, train, test):\n",
    "    \n",
    "    value_list = list(tree.values())\n",
    "    key_list = list(tree.keys())\n",
    "    attr_values = np.unique(train[key_list[0]])\n",
    "    #print('Attr-'+str(attr_values))\n",
    "    count_attr = len(attr_values)\n",
    "\n",
    "    for key in key_list:\n",
    "        i = -1\n",
    "        for value in attr_values:\n",
    "            #print('key = '+str(key)+'-->value = '+str(value))\n",
    "            i += 1\n",
    "            # base case\n",
    "            if not isinstance(tree[key][value], dict) and (i+1) == count_attr:\n",
    "                return pruning_result(tree, train, test)\n",
    "            # recursive part\n",
    "            elif isinstance(tree[key][value], dict):\n",
    "                attr_list_train = filter_data(train, key, value)\n",
    "                attr_list_test = filter_data(test, key, value)\n",
    "                #print('\\n--before pruning--\\n'+str(tree[key][value]))\n",
    "                tree[key][value] = reduced_pruning(tree[key][value], attr_list_train, attr_list_test)\n",
    "                #branch = post_pruning(tree[key][value], attr_list_train, attr_list_test)\n",
    "                #print('\\n----after pruning----\\n'+str(tree[key][value]))\n",
    "                #tree = {key :{value : branch}}\n",
    "            \n",
    "        return pruning_result(tree, train, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train[label].values\n",
    "X = train[train.keys().drop(label)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.insert(len(X_train.columns), train.columns[-1], y_train, True)\n",
    "X_test.insert(len(X_test.columns), train.columns[-1], y_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_pruneDT = reduced_pruning(tree, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2B. Stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_kfold_validation(X_skf, y_skf):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    #i = 0\n",
    "    accuracy_dt1 = []\n",
    "    accuracy_dt2 = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_skf, y_skf):\n",
    "        #print(\"TRAIN:\", train_index[0], \"TEST:\", test_index[0])\n",
    "        f_train = train.iloc[train_index]\n",
    "        f_test = train.iloc[test_index]\n",
    "        d_tree = decision_tree(f_train)\n",
    "        accuracy, report = correct_and_error(d_tree, f_test, 0)\n",
    "        accuracy_dt1.append(accuracy)\n",
    "        \n",
    "        Y = f_train[label].values\n",
    "        X = f_train[train.keys().drop(label)]\n",
    "        Xf_train, Xf_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "        Xf_train.insert(len(Xf_train.columns), train.columns[-1], y_train, True)\n",
    "        Xf_test.insert(len(Xf_test.columns), train.columns[-1], y_test, True)\n",
    "        \n",
    "        d_tree = reduced_pruning(d_tree, Xf_train, Xf_test)\n",
    "        accuracy, report = correct_and_error(d_tree, f_test, 0)\n",
    "        accuracy_dt2.append(accuracy)\n",
    "        #c_count, e_count = correct_and_eroor\n",
    "        #print(accuracy_t)\n",
    "        #i += 1\n",
    "    \n",
    "    return accuracy_dt1, accuracy_dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1, accuracy2 = strat_kfold_validation(X_train, y_train)\n",
    "\n",
    "#The warning below is due to the reason that the training data set has a category with only 2 members\n",
    "#And that can't be split in 10 ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of kfolds decision trees and their pruned DTs respectively\n",
    "\n",
    "print(accuracy1)\n",
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot lines \n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "plt.plot(x, accuracy1, label = \"Without Pruning\") \n",
    "plt.plot(x, accuracy2, label = \"With Pruning\") \n",
    "plt.legend() \n",
    "\n",
    "plt.xlabel('K-Folds') \n",
    "plt.ylabel('Accuracy') \n",
    "\n",
    "plt.title('Entropy Model with Stratified Kfold test accuracy')\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('Entropy.png')\n",
    "#print('Plot is saved as Entropy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2C. Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_entropy_dt, report1 = correct_and_error(entropy_DT, test, 1)\n",
    "print('Accuracy of Decision Tree without pruning: '+str(accuracy_entropy_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_entropy_pruned, report2 = correct_and_error(entropy_pruneDT, test, 1)\n",
    "print('Accuracy of Decision Tree without pruning: '+str(accuracy_entropy_pruned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m Entropy Model without Pruning \\033[0m\".center(70), end = \"\\n\\n\")\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m Entropy Model with Pruning \\033[0m\".center(70), end = \"\\n\\n\")\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>END</center></h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
